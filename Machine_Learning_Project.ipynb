{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f8054",
   "metadata": {
    "id": "729f8054"
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import nltk\n",
    "from nltk import ngrams, pos_tag, ne_chunk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59500d63",
   "metadata": {
    "id": "59500d63"
   },
   "source": [
    "# Task 1. Data understanding\n",
    "1 Download a csv file.  \n",
    "2 Load this dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae46ba2",
   "metadata": {
    "id": "9ae46ba2"
   },
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "# If using google colab, the '22204768.csv' file needs to be uploaded first\n",
    "complete_data = pd.read_csv('22204768.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d040a5ba",
   "metadata": {
    "id": "d040a5ba"
   },
   "source": [
    "###  Column selection:\n",
    "\n",
    "Columns that contain textual content are critical for this classification task. In this case, the 'headline' and 'short_description' columns are particularly valuable for this analysis.\n",
    "\n",
    "### 'headline' column\n",
    "### 'headline' + 'short_description' columns\n",
    "\n",
    "To conduct a comprehensive analysis, I will create two types of variables:\n",
    "\n",
    "1. data_headline Variable: keeping only the 'headline' column textual information\n",
    "2. data_combined Variable: It merges the 'headline' and 'short_description' columns to creat a new columns.\n",
    "\n",
    "I will try both variables in (i) data understanding, (ii) data preparation & modelling part.\n",
    "\n",
    "### As can be seen later from the results, the data_combined works better.\n",
    "\n",
    "There are some features analyzed that would make more sense using data_headline, such as sentence length.This provides insights into the effectiveness of headlines and their potential relationship with article categories.\n",
    "\n",
    "By considering both types of variables, I can experiment and compare the results to see which approach yields better performance or provides more meaningful insights for my classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d66d96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "48d66d96",
    "outputId": "c67d8092-0e3e-43c8-eaa3-9016696dfcf8"
   },
   "outputs": [],
   "source": [
    "# Select the 'headline' and 'category' columns\n",
    "data_headline = complete_data[['headline','category']]\n",
    "data_headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d96d367",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "8d96d367",
    "outputId": "e516aa7e-924b-4112-8664-d2c63472451d"
   },
   "outputs": [],
   "source": [
    "# Select the 'headline', 'short_description', and 'category' columns\n",
    "data_combined = complete_data.copy()\n",
    "data_combined = complete_data[['headline', 'short_description', 'category']]\n",
    "data_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2bd8b",
   "metadata": {
    "id": "70f2bd8b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creat a new column called 'combined_text'\n",
    "data_combined = complete_data[['headline', 'short_description', 'category']].copy()\n",
    "data_combined = data_combined.reset_index(drop=True)\n",
    "data_combined.loc[:, 'combined_text'] = data_combined['headline'] + ' ' + data_combined['short_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9585fb2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9585fb2b",
    "outputId": "5419fb37-b675-4e3f-805c-1bf8428fb858"
   },
   "outputs": [],
   "source": [
    "# Check the number of missing values\n",
    "data_combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a51de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "827a51de",
    "outputId": "bf0d64eb-fb47-40d2-bc5d-2243c7595905",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count the occurrences of each category\n",
    "# It is imbalanced\n",
    "data_headline['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21056731",
   "metadata": {
    "id": "21056731"
   },
   "outputs": [],
   "source": [
    "# Remove empty rows\n",
    "data_headline = data_headline.dropna()\n",
    "data_combined = data_combined.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f9314",
   "metadata": {
    "id": "996f9314"
   },
   "outputs": [],
   "source": [
    "# Filter the WELLNESS and DIVORCE classes\n",
    "head_WELLNESS_class = data_headline[data_headline['category']== 'WELLNESS']['headline']\n",
    "head_DIVORCE_class = data_headline[data_headline['category']== 'DIVORCE']['headline']\n",
    "\n",
    "comb_WELLNESS_class = data_combined[data_combined['category']== 'WELLNESS']['combined_text']\n",
    "comb_DIVORCE_class = data_combined[data_combined['category']== 'DIVORCE']['combined_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456db9a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "456db9a0",
    "outputId": "eb4463a5-092d-41df-b9a7-7af4ec2b231c"
   },
   "outputs": [],
   "source": [
    "head_DIVORCE_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a786f457",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a786f457",
    "outputId": "8e555621-c86d-408a-b107-2b8cffec4ae0"
   },
   "outputs": [],
   "source": [
    "comb_DIVORCE_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aebe73",
   "metadata": {
    "id": "91aebe73"
   },
   "source": [
    "# Task 1. Data understanding\n",
    "\n",
    "3 Perform an exploration of the data.  \n",
    "i) Perform an analysis of the most common terms. Preprocess the text.  \n",
    "ii) Analyzing other features. Analyse the length of the sentences.\n",
    "\n",
    "The steps I have chosen for data exploration are based on the provided links and the knowledge I gained from my previous AI and human language processing courses.\n",
    "\n",
    "### Preprocessing the text :\n",
    "lowercasing,   \n",
    "stemming,   \n",
    "lemmatization,   \n",
    "stopword removal,   \n",
    "punctuation removal, etc.  \n",
    "\n",
    "\n",
    "### Features analysised :\n",
    "the most common words,    \n",
    "the less common words,  \n",
    "sentence length,   \n",
    "N-grams,   \n",
    "POS tags,  \n",
    "sentiment analysis, etc.   \n",
    "\n",
    "iii) Check the blank values, incorrect data, and outliers.  \n",
    "I removed the blank values already.   \n",
    "I will check incorrect data and outliers in the following part.\n",
    "\n",
    "iv) Comment on your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb5334c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acb5334c",
    "outputId": "5cb3588c-ac3d-469e-e4c9-d0064a7f4637"
   },
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17722f33",
   "metadata": {
    "id": "17722f33"
   },
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "\n",
    "    # Removing punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Stopword removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Joining tokens back into text\n",
    "    processed_text = ' '.join(tokens)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e8868",
   "metadata": {
    "id": "8f2e8868"
   },
   "outputs": [],
   "source": [
    "# Apply text preprocessing\n",
    "head_WELLNESS_prep = head_WELLNESS_class.apply(preprocess_text)\n",
    "head_DIVORCE_prep = head_DIVORCE_class.apply(preprocess_text)\n",
    "comb_WELLNESS_prep = comb_WELLNESS_class.apply(preprocess_text)\n",
    "comb_DIVORCE_prep = comb_DIVORCE_class.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f97ad85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f97ad85",
    "outputId": "b933cc82-a7ba-4160-cf21-74054bb906ac"
   },
   "outputs": [],
   "source": [
    "head_WELLNESS_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a610f73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a610f73",
    "outputId": "a10e7bc5-7cac-4e75-8840-44bb24fb52d4"
   },
   "outputs": [],
   "source": [
    "head_WELLNESS_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a04eefa",
   "metadata": {
    "id": "2a04eefa"
   },
   "source": [
    "### data_headline exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff234383",
   "metadata": {
    "id": "ff234383"
   },
   "outputs": [],
   "source": [
    "# Initialize the vectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c279bd5",
   "metadata": {
    "id": "1c279bd5"
   },
   "outputs": [],
   "source": [
    "# Vectorize the head_WELLNESS_class\n",
    "words_in_head_WELLNESS = vectorizer.fit_transform(head_WELLNESS_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed039c1a",
   "metadata": {
    "id": "ed039c1a"
   },
   "outputs": [],
   "source": [
    "tokens_and_counts = zip(vectorizer.get_feature_names_out(), np.asarray(words_in_head_WELLNESS.sum(axis=0)).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3930180a",
   "metadata": {
    "id": "3930180a"
   },
   "outputs": [],
   "source": [
    "tokens_head_WELLNESS = pd.DataFrame(tokens_and_counts, columns=['Token', 'Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a3648f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "87a3648f",
    "outputId": "ce5495f3-bcc1-47e0-e8bd-a2350f6c8d30"
   },
   "outputs": [],
   "source": [
    "tokens_head_WELLNESS.sort_values(\"Count\", ascending=False, inplace=True)\n",
    "tokens_head_WELLNESS.reset_index(inplace=True, drop=True)\n",
    "tokens_head_WELLNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aca8aaa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "0aca8aaa",
    "outputId": "22c595a3-0490-439f-f2d2-a2e9abfe84ab"
   },
   "outputs": [],
   "source": [
    "most_common_head_WELLNESS = tokens_head_WELLNESS.nlargest(columns=\"Count\", n=10)\n",
    "most_common_head_WELLNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa535be3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "fa535be3",
    "outputId": "8db3a6fe-997c-47f3-814e-c2f84ae8aa07",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "least_common_head_WELLNESS = tokens_head_WELLNESS.nsmallest(columns=\"Count\", n=10)\n",
    "least_common_head_WELLNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e03f831",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "9e03f831",
    "outputId": "5a38401f-cded-45a5-91b6-47061a27f9aa"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(10,8))\n",
    "sns.barplot(ax=axes[0], data=least_common_head_WELLNESS, x=\"Token\", y =\"Count\")\n",
    "sns.barplot(ax=axes[1], data=most_common_head_WELLNESS, x=\"Token\", y =\"Count\")\n",
    "axes[0].set(ylabel='Counts', xlabel=\"Tokens\", title=\"%d Least Frequent Tokens After Text Preprocess\" % 10 )\n",
    "axes[1].set(ylabel='Counts', xlabel=\"Tokens\", title=\"%d Most Frequent Tokens After Text Preprocess\" % 10 )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29b1ac5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "f29b1ac5",
    "outputId": "6d671936-eca5-4260-d2f1-8d8d8c5005b3"
   },
   "outputs": [],
   "source": [
    "# Vectorize the head_DIVORCE_class\n",
    "words_in_head_DIVORCE = vectorizer.fit_transform(head_DIVORCE_prep)\n",
    "tokens_and_counts = zip(vectorizer.get_feature_names_out(), np.asarray(words_in_head_DIVORCE.sum(axis=0)).ravel())\n",
    "tokens_head_DIVORCE = pd.DataFrame(tokens_and_counts, columns=['Token', 'Count'])\n",
    "tokens_head_DIVORCE.sort_values(\"Count\", ascending=False, inplace=True)\n",
    "tokens_head_DIVORCE.reset_index(inplace=True, drop=True)\n",
    "tokens_head_DIVORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9171fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "6d9171fd",
    "outputId": "7f1d89a9-d9a0-4e87-8788-933fc8087e46"
   },
   "outputs": [],
   "source": [
    "most_common_head_DIVORCE = tokens_head_DIVORCE.nlargest(columns=\"Count\", n=10)\n",
    "most_common_head_DIVORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dedd64e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "1dedd64e",
    "outputId": "91d3e22c-d0f9-44a6-93f2-61845f9b0162"
   },
   "outputs": [],
   "source": [
    "least_common_head_DIVORCE = tokens_head_DIVORCE.nsmallest(columns=\"Count\", n=10)\n",
    "least_common_head_DIVORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f30775",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "f1f30775",
    "outputId": "be3295c1-cf49-47df-ee9e-087a75aecc5b"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(10,8))\n",
    "sns.barplot(ax=axes[0], data=least_common_head_DIVORCE, x=\"Token\", y =\"Count\")\n",
    "sns.barplot(ax=axes[1], data=most_common_head_DIVORCE, x=\"Token\", y =\"Count\")\n",
    "axes[0].set(ylabel='Counts', xlabel=\"Tokens\", title=\"%d Least Frequent Tokens After Text Preprocess\" % 10 )\n",
    "axes[1].set(ylabel='Counts', xlabel=\"Tokens\", title=\"%d Most Frequent Tokens After Text Preprocess\" % 10 )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba633f5",
   "metadata": {
    "id": "eba633f5"
   },
   "outputs": [],
   "source": [
    "# Calculate the length of sentences in each category\n",
    "# use the variable without text preprocessing\n",
    "head_WELLNESS_lengths = head_WELLNESS_class.apply(lambda x: len(x.split()))\n",
    "head_DIVORCE_lengths = head_DIVORCE_class.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd856f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "cdd856f2",
    "outputId": "8c4b3a5c-085f-4188-b545-6a4df7c167e5"
   },
   "outputs": [],
   "source": [
    "# Create a box plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot([head_WELLNESS_lengths, head_DIVORCE_lengths])\n",
    "plt.xticks([1, 2], ['WELLNESS', 'DIVORCE'])\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Sentence Length')\n",
    "plt.title('Distribution of Sentence Lengths in Each Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4098dc34",
   "metadata": {
    "id": "4098dc34"
   },
   "source": [
    "### incorrect data and outliers\n",
    "Outliers are represented as individual points outside the \"whiskers\" of the box plot. The whiskers extend to the data points that are within a specific distance from the first quartile (Q1) and the third quartile (Q3) of the data.  \n",
    "There doesn't appear to be any obvious incorrect data.    \n",
    "For Outliers, there are some outliers present. However, despite their presence, I have made the decision to retain these outliers as they still hold valuable information for the analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2197bcf4",
   "metadata": {
    "id": "2197bcf4"
   },
   "outputs": [],
   "source": [
    "# N-grams analysis\n",
    "def analyze_ngrams(text, n):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    n_grams = list(ngrams(tokens, n))\n",
    "    return n_grams\n",
    "\n",
    "head_WELLNESS_ngrams = []\n",
    "head_DIVORCE_ngrams = []\n",
    "\n",
    "for text in head_WELLNESS_prep:\n",
    "    head_WELLNESS_ngrams.extend(analyze_ngrams(text, 2))\n",
    "\n",
    "for text in head_DIVORCE_prep:\n",
    "    head_DIVORCE_ngrams.extend(analyze_ngrams(text, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd938c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cecd938c",
    "outputId": "949d265b-6ef4-48e6-8807-c35334a4d232"
   },
   "outputs": [],
   "source": [
    "# Plotting N-grams\n",
    "def plot_ngrams(ngrams, title):\n",
    "    freq_dist = nltk.FreqDist(ngrams)\n",
    "    freq_dist.plot(20, title=title)\n",
    "\n",
    "plot_ngrams(head_WELLNESS_ngrams, \"WELLNESS N-grams\")\n",
    "plot_ngrams(head_DIVORCE_ngrams, \"DIVORCE N-grams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b6355b",
   "metadata": {
    "id": "09b6355b"
   },
   "outputs": [],
   "source": [
    "# POS tagging\n",
    "def analyze_pos_tags(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    return pos_tags\n",
    "\n",
    "head_WELLNESS_pos = []\n",
    "head_DIVORCE_pos = []\n",
    "\n",
    "for text in head_WELLNESS_prep:\n",
    "    head_WELLNESS_pos.extend(analyze_pos_tags(text))\n",
    "\n",
    "for text in head_DIVORCE_prep:\n",
    "    head_DIVORCE_pos.extend(analyze_pos_tags(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95068d6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "id": "95068d6d",
    "outputId": "4749c65e-b8a6-4600-d62f-f7f440d4581d"
   },
   "outputs": [],
   "source": [
    "# Plotting POS tags\n",
    "def plot_pos_tags(pos_tags, title):\n",
    "    tags = [tag for (_, tag) in pos_tags]\n",
    "    freq_dist = nltk.FreqDist(tags)\n",
    "    freq_dist.plot(20, title=title)\n",
    "\n",
    "plot_pos_tags(head_WELLNESS_pos, \"WELLNESS POS Tags\")\n",
    "plot_pos_tags(head_DIVORCE_pos, \"DIVORCE POS Tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a021d",
   "metadata": {
    "id": "1c9a021d"
   },
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "head_WELLNESS_sentiments = [sia.polarity_scores(text)[\"compound\"] for text in head_WELLNESS_prep]\n",
    "head_DIVORCE_sentiments = [sia.polarity_scores(text)[\"compound\"] for text in head_DIVORCE_prep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ff48f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "500ff48f",
    "outputId": "8df25ed1-5f79-4670-ead4-340e1b4bffd9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting Sentiments\n",
    "def plot_sentiments(sentiments, category):\n",
    "    plt.hist(sentiments, bins=10, alpha=0.5, label=category)\n",
    "    plt.xlabel(\"Sentiment Score\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Sentiment Analysis\")\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "plot_sentiments(head_WELLNESS_sentiments, \"WELLNESS\")\n",
    "plot_sentiments(head_DIVORCE_sentiments, \"DIVORCE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff8c959",
   "metadata": {
    "id": "9ff8c959"
   },
   "source": [
    "### iv)  Comment for data_headline exploration.\n",
    "The analysis of the two categories, WELLNESS and DIVORCE, reveals several noteworthy differences in their linguistic characteristics and textual patterns.  \n",
    "\n",
    "Firstly, examining the most common words in each category indicates distinct thematic focuses. For the \"Wellness\" category, the most common words include \"study,\" \"health,\" \"life,\" \"way,\" \"sleep,\" \"new,\" \"cancer,\" \"make,\" \"day,\" and \"weight.\" These terms are often associated with topics related to general well-being, healthy lifestyle choices, and self-improvement.In the \"Divorce\" category, the most common words include \"divorce,\" \"marriage,\" \"date,\" \"woman,\" \"ex,\" \"photo,\" \"cheat,\" \"video,\" \"parent,\" and \"relationship.\" These terms are closely related to the process and aftermath of divorce, including discussions about marriage, separation, and the emotional aspects of ending a relationship.\n",
    "\n",
    "Analyzing the sentence length in each category demonstrates potential variations in structure. It appears that the \"Divorce\" category tends to have slightly longer sentences compared to the \"Wellness\" category. for sentence length outliers, there are some outliers present. However, despite their presence, I have made the decision to retain these outliers as they still hold valuable information for the analysis.\n",
    "\n",
    "Exploring N-grams, sequences of consecutive words, provided a deeper understanding of linguistic patterns. Examining the top N-grams in wellness category, like \"study find\" \"lose weight\" indicating a focus on research and general well-being and general health.  In contrast, the top N-grams in the \"divorce\" category appear with \"date divorce\" \"blend family\". Both are very representative.\n",
    "\n",
    "POS tagging provides insights into the syntactic structure and grammatical patterns present in the texts. Analyzing the distribution of POS tags in each category helps identify differences in the usage of nouns, verbs, adjectives, and other linguistic elements. The Part-of-Speech (POS) analysis reveals that the distribution of POS tags is relatively similar for both categories.\n",
    "\n",
    "Sentiment analysis revealed the overall sentiment polarity of the texts in each category. Curiously, the sentiment scores in the \"wellness\" category were clustered between -0.25 and 0, indicating a slight negative and neutral sentiment. On the other hand, the sentiment scores in the \"divorce\" category tended to cluster in the range of 0 to 0.25, indicating a mixture of neutral to mildly positive sentiments.\n",
    "\n",
    "In conclusion, the analysis of various textual features highlights distinct linguistic patterns and thematic differences between the WELLNESS and DIVORCE categories. These insights can be valuable in developing effective classification models or understanding the underlying themes and subjects discussed within each category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e95855b",
   "metadata": {
    "id": "9e95855b"
   },
   "source": [
    "### data_combined exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e490c8c2",
   "metadata": {
    "id": "e490c8c2"
   },
   "outputs": [],
   "source": [
    "# Vectorize the comb_WELLNESS_class\n",
    "words_in_comb_WELLNESS = vectorizer.fit_transform(comb_WELLNESS_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3555c5",
   "metadata": {
    "id": "8b3555c5"
   },
   "outputs": [],
   "source": [
    "tokens_and_counts = zip(vectorizer.get_feature_names_out(), np.asarray(words_in_comb_WELLNESS.sum(axis=0)).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710d2528",
   "metadata": {
    "id": "710d2528"
   },
   "outputs": [],
   "source": [
    "tokens_comb_WELLNESS = pd.DataFrame(tokens_and_counts, columns=['Token', 'Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da52255",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "2da52255",
    "outputId": "779e52bb-1c5e-427f-ec68-db850f8f3ef7"
   },
   "outputs": [],
   "source": [
    "tokens_comb_WELLNESS.sort_values(\"Count\", ascending=False, inplace=True)\n",
    "tokens_comb_WELLNESS.reset_index(inplace=True, drop=True)\n",
    "tokens_comb_WELLNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4931ed71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "4931ed71",
    "outputId": "acc8d1f8-0adb-447e-bd08-afb1ddd681f0"
   },
   "outputs": [],
   "source": [
    "most_common_comb_WELLNESS = tokens_comb_WELLNESS.nlargest(columns=\"Count\", n=10)\n",
    "most_common_comb_WELLNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff8f80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "deff8f80",
    "outputId": "f0066eee-4bc4-4465-bd89-d4859f89ea7f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "least_common_comb_WELLNESS = tokens_comb_WELLNESS.nsmallest(columns=\"Count\", n=10)\n",
    "least_common_comb_WELLNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa046e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "dfaa046e",
    "outputId": "b1f16a5a-03d5-4f39-f3d1-2afdeeb38283"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(10,8))\n",
    "sns.barplot(ax=axes[0], data=least_common_comb_WELLNESS, x=\"Token\", y =\"Count\")\n",
    "sns.barplot(ax=axes[1], data=most_common_comb_WELLNESS, x=\"Token\", y =\"Count\")\n",
    "axes[0].set(ylabel='Counts', xlabel=\"Tokens\", title=\"%d Least Frequent Tokens After Text Preprocess\" % 10 )\n",
    "axes[1].set(ylabel='Counts', xlabel=\"Tokens\", title=\"%d Most Frequent Tokens After Text Preprocess\" % 10 )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bd46b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "d7bd46b0",
    "outputId": "0f4526b5-202e-4db8-9a9d-b29e9db24a0d"
   },
   "outputs": [],
   "source": [
    "# Vectorize the comb_DIVORCE_class\n",
    "words_in_comb_DIVORCE = vectorizer.fit_transform(comb_DIVORCE_prep)\n",
    "tokens_and_counts = zip(vectorizer.get_feature_names_out(), np.asarray(words_in_comb_DIVORCE.sum(axis=0)).ravel())\n",
    "tokens_comb_DIVORCE = pd.DataFrame(tokens_and_counts, columns=['Token', 'Count'])\n",
    "tokens_comb_DIVORCE.sort_values(\"Count\", ascending=False, inplace=True)\n",
    "tokens_comb_DIVORCE.reset_index(inplace=True, drop=True)\n",
    "tokens_comb_DIVORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c257f7fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "c257f7fd",
    "outputId": "1e965725-9faa-4ef1-e9ae-49b35f5b7f58"
   },
   "outputs": [],
   "source": [
    "most_common_comb_DIVORCE = tokens_comb_DIVORCE.nlargest(columns=\"Count\", n=10)\n",
    "most_common_comb_DIVORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce576754",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "ce576754",
    "outputId": "25197610-7bc1-47ae-aa50-bf4e4a1d7ebc"
   },
   "outputs": [],
   "source": [
    "least_common_comb_DIVORCE = tokens_comb_DIVORCE.nsmallest(columns=\"Count\", n=10)\n",
    "least_common_comb_DIVORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d0e77c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "b9d0e77c",
    "outputId": "24140c87-d373-4216-f40f-fa6a86aa2fa0"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(10,8))\n",
    "sns.barplot(ax=axes[0], data=least_common_comb_DIVORCE, x=\"Token\", y =\"Count\")\n",
    "sns.barplot(ax=axes[1], data=most_common_comb_DIVORCE, x=\"Token\", y =\"Count\")\n",
    "axes[0].set(ylabel='Counts', xlabel=\"Tokens\", title=\"%d Least Frequent Tokens After Text Preprocess\" % 10 )\n",
    "axes[1].set(ylabel='Counts', xlabel=\"Tokens\", title=\"%d Most Frequent Tokens After Text Preprocess\" % 10 )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d07e4",
   "metadata": {
    "id": "bb3d07e4"
   },
   "outputs": [],
   "source": [
    "# There is not much sense in analyzing the sentence length of the merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef7114",
   "metadata": {
    "id": "00ef7114"
   },
   "outputs": [],
   "source": [
    "# N-grams analysis\n",
    "\n",
    "comb_WELLNESS_ngrams = []\n",
    "comb_DIVORCE_ngrams = []\n",
    "\n",
    "for text in comb_WELLNESS_prep:\n",
    "    comb_WELLNESS_ngrams.extend(analyze_ngrams(text, 2))\n",
    "\n",
    "for text in comb_DIVORCE_prep:\n",
    "    comb_DIVORCE_ngrams.extend(analyze_ngrams(text, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760ce11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0760ce11",
    "outputId": "cf4e79be-50eb-4599-b06d-d10830960bec"
   },
   "outputs": [],
   "source": [
    "# Plotting N-grams\n",
    "\n",
    "plot_ngrams(comb_WELLNESS_ngrams, \"WELLNESS N-grams\")\n",
    "plot_ngrams(comb_DIVORCE_ngrams, \"DIVORCE N-grams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b73f94",
   "metadata": {
    "id": "f5b73f94"
   },
   "outputs": [],
   "source": [
    "# POS tagging\n",
    "\n",
    "comb_WELLNESS_pos = []\n",
    "comb_DIVORCE_pos = []\n",
    "\n",
    "for text in comb_WELLNESS_prep:\n",
    "    comb_WELLNESS_pos.extend(analyze_pos_tags(text))\n",
    "\n",
    "for text in comb_DIVORCE_prep:\n",
    "    comb_DIVORCE_pos.extend(analyze_pos_tags(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed3a76d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "id": "6ed3a76d",
    "outputId": "aff20e02-d7d9-466f-9386-7abcfcf57e55"
   },
   "outputs": [],
   "source": [
    "# Plotting POS tags\n",
    "\n",
    "plot_pos_tags(comb_WELLNESS_pos, \"WELLNESS POS Tags\")\n",
    "plot_pos_tags(comb_DIVORCE_pos, \"DIVORCE POS Tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bfa3c6",
   "metadata": {
    "id": "98bfa3c6"
   },
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "comb_WELLNESS_sentiments = [sia.polarity_scores(text)[\"compound\"] for text in comb_WELLNESS_prep]\n",
    "comb_DIVORCE_sentiments = [sia.polarity_scores(text)[\"compound\"] for text in comb_DIVORCE_prep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab4b9d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "5ab4b9d7",
    "outputId": "e1b4abc3-e9fb-4eba-ff00-4bf360c80342",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting Sentiments\n",
    "\n",
    "plot_sentiments(comb_WELLNESS_sentiments, \"WELLNESS\")\n",
    "plot_sentiments(comb_DIVORCE_sentiments, \"DIVORCE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f8f4f",
   "metadata": {
    "id": "923f8f4f"
   },
   "source": [
    "### iv)  Comment for data_combined exploration.\n",
    "During the exploration of the data_combined dataset, similar to the data_headline exploration, we can observe significant differences in the most common words, less common words, and n-grams between the two categories.\n",
    "\n",
    "The advantage of the data_combined dataset is that it yields higher counts and greater variations. By combining the headline and short_description columns, we obtain a more extensive text representation that captures additional information and context from the articles. This increased amount of data leads to a richer and more comprehensive analysis, potentially enhancing the performance of subsequent tasks such as classification.\n",
    "\n",
    "Furthermore, the Sentiment Analysis results reveal a more possible pattern. The WELLNESS category exhibits more positive sentiment scores.\n",
    "\n",
    "These differences indicate that combining the headline and short_description columns provides a more comprehensive representation of the articles, capturing additional information that can contribute to our analysis.\n",
    "\n",
    "### data_combined has greater data variation and should be more useful for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea46fa89",
   "metadata": {
    "id": "ea46fa89"
   },
   "source": [
    "# Task 2. Data Preparation & Modelling\n",
    "4. Splitting the dataset into training, development and test sets.  \n",
    "i) Choose an appropriate split. Comment on your choices.     \n",
    "ii) Save your data as separate csv files.\n",
    "\n",
    "5. Load csv files. Text preprocessing.Apply appropriate preprocessing steps to create a numeric representation of the documents, suitable for classification.\n",
    "I will use the text preprocessing function from before.\n",
    "\n",
    "### Use data_combined first, then try data_headline later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f261a0bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "id": "f261a0bf",
    "outputId": "ef29679f-fb58-4e8c-a90d-e1f7c211ce7f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c484e97",
   "metadata": {
    "id": "9c484e97"
   },
   "outputs": [],
   "source": [
    "X = data_combined['combined_text']\n",
    "y = data_combined['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596b402f",
   "metadata": {
    "id": "596b402f"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "X_train_plus_valid, X_test, y_train_plus_valid, y_test = train_test_split(X, y, random_state=0, test_size=0.2, train_size=0.8)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_plus_valid, y_train_plus_valid, random_state=0, test_size=0.25, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe0ce6",
   "metadata": {
    "id": "1ffe0ce6"
   },
   "source": [
    "The proportion of data segmentation is as follows:\n",
    "Training set: 75% of the original data.\n",
    "Validation set: 25% of the original data (split from the training set)\n",
    "Test set: 20% of the original data (split from the remaining data not used for training and validation)\n",
    "The choice of these percentages is a common practice in machine learning. Let me briefly explain why I split it this way:\n",
    "\n",
    "Training set: The largest portion of the data is allocated to the training set (75%). This allows the model to learn patterns and relationships in the data more effectively because it has access to a large number of labeled examples.\n",
    "Validation set: A small portion (25%) is assigned to the validation set. It is used to fine-tune the model and to evaluate its performance during training. The validation set helps to select the best model.\n",
    "Test set: After the model training and hyperparameter tuning is completed, the test set is completely separated until the final evaluation phase. to obtain an unbiased estimate of its performance on unseen data.\n",
    "With this partitioning, we can ensure that the model is trained on a sufficiently large training set, validated on a separate data set for hyperparameter tuning, and evaluated on a completely separate test set to assess its generalization ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a16d3",
   "metadata": {
    "id": "dd0a16d3"
   },
   "outputs": [],
   "source": [
    "# Save the data as separate CSV files\n",
    "train_data = pd.DataFrame({'combined_text': X_train, 'category': y_train})\n",
    "valid_data = pd.DataFrame({'combined_text': X_valid, 'category': y_valid})\n",
    "test_data = pd.DataFrame({'combined_text': X_test, 'category': y_test})\n",
    "\n",
    "train_data.to_csv('train.csv', index=False)\n",
    "valid_data.to_csv('valid.csv', index=False)\n",
    "test_data.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea9201",
   "metadata": {
    "id": "63ea9201"
   },
   "outputs": [],
   "source": [
    "# Load the data from CSV files\n",
    "train_data = pd.read_csv('train.csv')\n",
    "valid_data = pd.read_csv('valid.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc0a079",
   "metadata": {
    "id": "cdc0a079",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply preprocessing to the text data\n",
    "train_data['preprocessed_text'] = train_data['combined_text'].apply(preprocess_text)\n",
    "valid_data['preprocessed_text'] = valid_data['combined_text'].apply(preprocess_text)\n",
    "test_data['preprocessed_text'] = test_data['combined_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bebb6e",
   "metadata": {
    "id": "68bebb6e"
   },
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target variable (y)\n",
    "X_train = train_data['preprocessed_text']\n",
    "X_valid = valid_data['preprocessed_text']\n",
    "X_test = test_data['preprocessed_text']\n",
    "y_train = train_data['category']\n",
    "y_valid = valid_data['category']\n",
    "y_test = test_data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a5a94",
   "metadata": {
    "id": "f55a5a94"
   },
   "outputs": [],
   "source": [
    "# Create a numeric representation of the documents\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_matrix = vectorizer.fit_transform(train_data['preprocessed_text'])\n",
    "X_valid_matrix = vectorizer.transform(valid_data['preprocessed_text'])\n",
    "X_test_matrix = vectorizer.transform(test_data['preprocessed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf1290b",
   "metadata": {
    "id": "abf1290b"
   },
   "outputs": [],
   "source": [
    "# Encode the target variable into numeric labels\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "# y_valid_encoded = label_encoder.transform(y_valid)\n",
    "# y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ba628",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba2ba628",
    "outputId": "fb2c8345-7898-49f6-9cda-09be65f0c70c"
   },
   "outputs": [],
   "source": [
    "print(X_train_matrix.shape)\n",
    "print(X_valid_matrix.shape)\n",
    "print(X_test_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0564997d",
   "metadata": {
    "id": "0564997d"
   },
   "source": [
    "# Task 2. Data Preparation & Modelling\n",
    "\n",
    "6. Build binary classification models using two classifiers.Comment on your choices for the classifier and parameters used in each classifier.\n",
    "\n",
    "In this task, I experimented with five different classifiers to classify news articles into two categories.\n",
    "Find the two classifiers that performed the best.\n",
    "\n",
    "### Five tested classifiers:   \n",
    "1 Logistic Regression  \n",
    "2 Random Forest  \n",
    "3 Support Vector Machine (SVM)  \n",
    "4 Naive Bayes  \n",
    "5 K-Nearest Neighbors (KNN)  \n",
    "\n",
    "### Choices for parameters\n",
    "1 Logistic Regression:      \n",
    "all default parameters, which generally work well for many classification tasks.  \n",
    "2 Random Forest:  \n",
    "set the number of estimators (n_estimators) to 100. Increasing the number of estimators can potentially improve the model's performance, but it comes with a higher computational cost. 100 is a common value that provides a good balance between accuracy and efficiency.  \n",
    "3 Support Vector Machine (SVM):  \n",
    "kernel='linear'. The linear kernel works well when the classes are well-separated in the feature space.   \n",
    "4 Naive Bayes:  \n",
    "the classifier's default settings are suitable for this task.  \n",
    "5 K-Nearest Neighbors (KNN):  \n",
    "the classifier's default settings are suitable for this task.\n",
    "\n",
    "\n",
    "7. Build or apply an end-to-end classifier using deep learning. You can either train your own deep learning model from scratch or fine-tune an existing model. Save this model in an appropriate format.\n",
    "\n",
    "### Deep Learning\n",
    "Since deep learning requires too much computing power and my laptop can't support it.   \n",
    "I switched to colab but the training takes too long and often reconnects. After ran it for several days, I finally managed to store my first model.   \n",
    "I separated the deep learning model training individually in the end. And for the later tasks, I will no longer adjust the model.  \n",
    "\n",
    "### Two final choices of classifiers: Random Forest and Naive Bayes\n",
    "After evaluating the classification reports, the two classifiers that stand out as the best performers are Random Forest and Naive Bayes. Both classifiers consistently demonstrate high precision, recall, and F1-score for both classes (DIVORCE and WELLNESS). They maintain a good balance in classifying articles from both categories.\n",
    "\n",
    "Therefore, I have chosen Random Forest and Naive Bayes as the top two classifiers for this task, as they exhibit strong and consistent performance in classifying the news articles into the correct topical categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65625015",
   "metadata": {
    "id": "65625015"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29564b9",
   "metadata": {
    "id": "d29564b9"
   },
   "outputs": [],
   "source": [
    "# Initialize the classifiers with desired parameters\n",
    "logreg = LogisticRegression()\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "naive_bayes = MultinomialNB()\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a97b9ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "9a97b9ca",
    "outputId": "b161a58f-59f7-4551-bdbd-ee6b4a9d5a89"
   },
   "outputs": [],
   "source": [
    "# Train the Logistic Regression classifier\n",
    "logreg.fit(X_train_matrix, y_train)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "rf.fit(X_train_matrix, y_train)\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm_classifier.fit(X_train_matrix, y_train)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "naive_bayes.fit(X_train_matrix, y_train)\n",
    "\n",
    "# Train the K-Nearest Neighbors classifier\n",
    "knn.fit(X_train_matrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d678ae",
   "metadata": {
    "id": "b6d678ae"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the validation set\n",
    "logreg_pred = logreg.predict(X_valid_matrix)\n",
    "rf_pred = rf.predict(X_valid_matrix)\n",
    "svm_pred = svm_classifier.predict(X_valid_matrix)\n",
    "nb_pred = naive_bayes.predict(X_valid_matrix)\n",
    "knn_pred = knn.predict(X_valid_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94530c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4a94530c",
    "outputId": "a3a76e4f-3f3e-4561-c9f9-894b79997a0c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print classification report for each classifier\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_valid, logreg_pred))\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_valid, rf_pred))\n",
    "\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_valid, svm_pred))\n",
    "\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_valid, nb_pred))\n",
    "\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_valid, knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9853e074",
   "metadata": {
    "id": "9853e074"
   },
   "source": [
    "### Check train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30d016a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b30d016a",
    "outputId": "8593d416-ace2-4d68-c01e-a96f9ba796e8"
   },
   "outputs": [],
   "source": [
    "# Make predictions on the train set\n",
    "rf_train_pred = rf.predict(X_train_matrix)\n",
    "nb_train_pred = naive_bayes.predict(X_train_matrix)\n",
    "\n",
    "print(\"Random Forest Classification Report - Train Set:\")\n",
    "print(classification_report(y_train, rf_train_pred))\n",
    "print(\"Naive Bayes Classification Report - Train Set:\")\n",
    "print(classification_report(y_train, nb_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24929a75",
   "metadata": {
    "id": "24929a75"
   },
   "source": [
    "### Task 2. Data Preparation & Modelling\n",
    "7. Build or apply an end-to-end classifier using deep learning. For this task, you can either train your own deep learning model from scratch or fine-tune an existing model. Save this model in an appropriate format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c06287",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28c06287",
    "outputId": "a329397f-a959-4fad-aa3e-f7c499894a60"
   },
   "outputs": [],
   "source": [
    "# Use Colab to run, my computer is not able to run\n",
    "\n",
    "! pip install transformers\n",
    "from transformers import AutoTokenizer, TFDistilBertForSequenceClassification\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54e83fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "15e3063792734807986fd1530a75c452",
      "bd0a5ef2c11b4a2eb93de4c807abcaaa",
      "24f1f3b659bc4da397d50729982f8430",
      "1a86f28be5f54a86b7bdb73a749fc0c5",
      "e3abc8d8583f4b768b5879a2397563e2",
      "8021d6aeb0cb4db890b838b82a2ba2a5",
      "fbab4b6c320346f1b2916897f3a73de8",
      "807c617a65c243868cf84d9cf89be176",
      "2389b572c2a94217bd23c264e3da38ca",
      "1b799d514ccf43bfa9177688ee201b10",
      "d6deb3b9278548fa8d49ea838dce3140",
      "7c50cef2d78049dea3b77d6a27e70dec",
      "714c5a96d58f4657bc256f1d6235e013",
      "b380d5cbd77b4f6c85d0bbcdce3338d5",
      "ca1d90c8c2f041eba8c0e266995357c5",
      "70271c3a3dd142cba58b92d914219323",
      "f8d1876599c449d7b09d925de8dce5df",
      "f4ea486b780a4c589ce2f038bb185c44",
      "4dd4b92cfc2f4b81ab06c71087076a91",
      "8ae7d6fc9e0a48ae9a5add7272700266",
      "8226e7242865452388cf94c9337acac3",
      "6f119c078cd04eceb91359bed333b8bc",
      "9e14fc8a597d4237abba924ff7ff109d",
      "f659e145fcf440c488adb41ba8673102",
      "9c4fe3867f034184aac40ab64211db40",
      "ca6aa7caab684114a3adfcf68d73d931",
      "924c7d3eaed24f02bdb3827d2abd2091",
      "2a0ad923fc5b4c9987d92686eb8488c0",
      "098053b17c9c4cb2ad6c049a4a7dda98",
      "b3b32a8881774afab489196262b40ee1",
      "25c46f35a6ff482790013aa47c7ee18f",
      "37ecdb71727c4c9ab9ae18f16b220f07",
      "f2f55bd2f61249cc8ca8763e1a9aee6c",
      "7c95b65a913c42fd839b14a6599644dc",
      "5612f89d795144aab940f68d80ea4445",
      "fce77630dceb4ae89d9f9e6e4bccd5a6",
      "f64fcca7b8e840199f6912bc34303eb7",
      "277c96a787f94eb3b711c96e88a4a3dc",
      "2e8063ec408c4b4c97349cb3ea9f4bdb",
      "58373f4baa9c4ce1978479c0fa06f1a2",
      "f498562eb3e34a9eaded9244ef7451ff",
      "f525cdffdab34959903d1532d656eb82",
      "29ee23ef36c34d4c83d8d1c47f79d4b1",
      "9195c7c7d3024f64a0e24c9988f8c1c0"
     ]
    },
    "id": "e54e83fd",
    "outputId": "7f4c5b78-f69e-4ea2-d640-54ef74031383"
   },
   "outputs": [],
   "source": [
    "# Apply preprocessing to the text data\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# Tokenize the input text and create TensorFlow datasets\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True)\n",
    "valid_encodings = tokenizer(X_valid.tolist(), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(X_test.tolist(), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1409cd52",
   "metadata": {
    "id": "1409cd52"
   },
   "outputs": [],
   "source": [
    "# Encode the target variable into numeric labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_valid_encoded = label_encoder.transform(y_valid)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd261ae0",
   "metadata": {
    "id": "fd261ae0"
   },
   "outputs": [],
   "source": [
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train_encoded))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((dict(valid_encodings), y_valid_encoded))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f352383d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154,
     "referenced_widgets": [
      "792faff836784e0f82736f3675d8f2d8",
      "338bd01628cd420a9361132353e2e5ed",
      "3a40668ee2184d32ac2770ce699410fe",
      "05ce559368b84fd39c47f8fb6a5e1d58",
      "66b29aa5d9a2450097a85b4e1b483977",
      "8e6a0e1cb91648a7a552c3808216ba9f",
      "70e12c85496a4ec986bbb01f74ba6b53",
      "a27a54842c664d30ad3ce4620287d170",
      "eeebc74362664bd7a87bae4b72be48da",
      "4546299f5016478eb63705da96f7bc1a",
      "791ee0ecdfcd4c808bba9f4ea1e90e53"
     ]
    },
    "id": "f352383d",
    "outputId": "a6b41027-89bd-4291-c9d6-ddeb71e7aa76"
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained DistilBERT model for sequence classification\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124639cd",
   "metadata": {
    "id": "124639cd"
   },
   "source": [
    "The pre-trained DistilBERT model can be fine-tuned on specific downstream tasks such as text classification, sentiment analysis, question answering, and more. By leveraging the pre-trained knowledge from the large corpus, the DistilBERT model can be adapted and specialized for specific NLP tasks with less training data and computational resources compared to training from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253a314",
   "metadata": {
    "id": "e253a314"
   },
   "outputs": [],
   "source": [
    "# Define the optimizer, loss function, and metrics\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cece504",
   "metadata": {
    "id": "1cece504"
   },
   "source": [
    "Optimizer: The optimizer is responsible for updating the model's parameters during training to minimize the loss. In this case, the code uses the Adam optimizer, which is a popular optimization algorithm known for its efficiency in deep learning.\n",
    "Loss function: The loss function measures the discrepancy between the predicted output of the model and the true labels. It provides a measure of how well the model is performing during training.\n",
    "Metrics: Metrics are used to evaluate the performance of the model during training. They provide additional information about the model's accuracy or performance beyond the loss function. In this case, the code specifies the Sparse Categorical Accuracy as the metric. It computes the accuracy of the model's predictions by comparing them to the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c678f",
   "metadata": {
    "id": "711c678f"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5bc2eb",
   "metadata": {
    "id": "0c5bc2eb"
   },
   "outputs": [],
   "source": [
    "# You can skip and directly go to the Load Model step.\n",
    "\n",
    "# Train the model\n",
    "\n",
    "# Be careful. Google Colab takes half a day to complete this step.\n",
    "\n",
    "# The first set of parameters was more ideal, but there wasn't enough computational capacity.\n",
    "# It runs all day but constantly restarting/disconnected/failures. Couldn't get a result.\n",
    "# So tuned down the parameters.\n",
    "\n",
    "# model.fit(\n",
    "#     x=train_dataset.shuffle(1000).batch(16),\n",
    "#     validation_data=valid_dataset.batch(16),\n",
    "#     epochs=5\n",
    "# )\n",
    "\n",
    "model.fit(\n",
    "    x=train_dataset.shuffle(1000).batch(32),\n",
    "    validation_data=valid_dataset.batch(32),\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834a98f5",
   "metadata": {
    "id": "834a98f5"
   },
   "source": [
    "accuracy\n",
    "\n",
    "The output:\n",
    "Epoch 1/3\n",
    "149/149 [==============================] - 3264s 22s/step - loss: 0.2170 - accuracy: 0.9125 - val_loss: 0.1347 - val_accuracy: 0.9446\n",
    "Epoch 2/3\n",
    "149/149 [==============================] - 3206s 22s/step - loss: 0.0958 - accuracy: 0.9694 - val_loss: 0.1077 - val_accuracy: 0.9585\n",
    "Epoch 3/3\n",
    "149/149 [==============================] - 3182s 21s/step - loss: 0.0519 - accuracy: 0.9828 - val_loss: 0.1215 - val_accuracy: 0.9597\n",
    "<keras.callbacks.History at 0x7a6ddccaa5f0>\n",
    "\n",
    "High Accuracy: The model achieves high accuracy on both the training and validation datasets. In the last epoch, the training accuracy reaches 98.28%, and the validation accuracy is 95.97%. High accuracy on the validation set indicates that the model is generalizing well to unseen data, which is a positive sign.  \n",
    "Decreasing Loss: The training loss steadily decreases with each epoch, indicating that the model is effectively learning from the training data and minimizing its error. The validation loss also shows a decreasing trend, which suggests that the model is not overfitting to the training data.  \n",
    "Consistent Improvement: The accuracy and loss metrics consistently improve across the epochs. This behavior indicates that the model continues to learn and refine its predictions with additional training.  \n",
    "Reasonable Training Time: The training time per epoch seems reasonable, considering the loss and accuracy improvements achieved. Long training times can be a concern, but it depends on the complexity of the model and the available computing resources.  \n",
    "\n",
    "Overall, based on these accuracy values, the model appears to be performing well and achieving a high level of accuracy in classifying news articles into their respective topical categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df993d",
   "metadata": {
    "id": "06df993d"
   },
   "outputs": [],
   "source": [
    "# You can skip and directly go to the Load Model step.\n",
    "# Save the trained model in the same folder as the Jupyter Notebook\n",
    "model.save_pretrained('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb87913",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eb87913",
    "outputId": "70e0f570-d2a4-4478-dec8-2ccbfeedca60"
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = TFDistilBertForSequenceClassification.from_pretrained('./')\n",
    "\n",
    "# Display the model summary and configuration\n",
    "loaded_model.summary()\n",
    "loaded_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c23aab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89c23aab",
    "outputId": "5298a614-b04b-4710-f70d-80502660758a"
   },
   "outputs": [],
   "source": [
    "# Generate predictions on the validation set\n",
    "y_pred_valid = loaded_model.predict(valid_dataset.batch(16))\n",
    "y_pred_valid_labels = label_encoder.inverse_transform(tf.argmax(y_pred_valid.logits, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0bdf28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3a0bdf28",
    "outputId": "bcbca295-7687-49f3-d4d2-fe73f817e441"
   },
   "outputs": [],
   "source": [
    "# Generate the classification report on the validation set\n",
    "classification_report_valid = classification_report(y_valid, y_pred_valid_labels)\n",
    "print(\"Classification Report - Deep Learning (Validation Set):\")\n",
    "print(classification_report_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d9c3e",
   "metadata": {
    "id": "b15d9c3e"
   },
   "source": [
    "### Deep learning Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff421748",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "ff421748",
    "outputId": "fc8098eb-4ccc-4bb0-f695-6d2a08d237c6"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix for Deep learning\n",
    "cm_valid = confusion_matrix(y_valid, y_pred_valid_labels)\n",
    "ax_valid = plt.subplot()\n",
    "sns.heatmap(cm_valid, annot=True, fmt='g', ax=ax_valid)\n",
    "ax_valid.set_xlabel('Predicted labels')\n",
    "ax_valid.set_ylabel('True labels')\n",
    "ax_valid.set_title('Confusion Matrix - Deep Learning')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1b43bc",
   "metadata": {
    "id": "7f1b43bc"
   },
   "source": [
    "# Task 3. Evaluation\n",
    "\n",
    "8. Choose a primary metric that will be used to evaluate your models. Justify your choice. Comment on what is a good benchmark for this task.\n",
    "\n",
    "### Imbalanced dataset\n",
    "When dealing with an imbalanced dataset like this, accuracy alone may not provide an accurate representation of the classifier's performance. It is crucial to consider additional metrics to evaluate classification models on imbalanced datasets.\n",
    "\n",
    "The classification report provides detailed insights into the performance of each classifier. The important metrics include precision, recall, and F1-score. Precision measures the ability of the classifier to correctly identify positive instances, while recall measures the ability to capture all positive instances. F1-score provides a balance between precision and recall.\n",
    "\n",
    "Given that the categories in the dataset are imbalanced, with a larger number of articles in the \"WELLNESS\" category compared to the \"DIVORCE\" category, accuracy alone may not be the most informative metric. Instead, it is important to consider both precision and recall to assess the performance of the classifiers.\n",
    "\n",
    "If the goal is to minimize false positives (incorrectly classifying an article as \"DIVORCE\"), precision would be a crucial metric. On the other hand, if the goal is to minimize false negatives (incorrectly classifying an article as \"WELLNESS\"), recall becomes more important.\n",
    "\n",
    "To strike a balance between precision and recall, the F1-score (harmonic mean of precision and recall) could be a suitable primary metric for evaluation. It provides a single measure that considers both precision and recall, making it useful for imbalanced datasets where both false positives and false negatives are important.\n",
    "\n",
    "A good benchmark for this task could be based on domain expertise or existing research in the field. This benchmark could be used to compare the models' F1-scores and determine their effectiveness in classifying the news articles.\n",
    "\n",
    "9. Evaluate the performance of each model developed on Task 2 (items 6 and 7) on your train and validation sets. How does the performance on the train set compare to the validation set? Comment on the performance of the classifiers/models.\n",
    "In general, the performance on the validation set of those models is similar to the performance on the training set, except KNN, it suggests that the model is generalizing well.\n",
    "\n",
    "### Logistic Regression:\n",
    "Achieves high precision, recall, and F1-scores for both categories.\n",
    "The recall for the \"DIVORCE\" category is slightly lower on the validation set (0.85) .\n",
    "\n",
    "### Random Forest:\n",
    "Achieves high precision, recall, and F1-scores for both categories.\n",
    "A bit low for DOVORCE but still all over 0.9. Very high for WELLNESS.\n",
    "Shows strong performance in classifying both \"DIVORCE\" and \"WELLNESS\" articles.\n",
    "\n",
    "### SVM:\n",
    "Achieves high precision, recall, and F1-scores for both categories.\n",
    "A bit low for DIVORCE recall which is 0.87.\n",
    "\n",
    "### Naive Bayes:\n",
    "Achieves high precision, recall, and F1-scores for both categories.\n",
    "A bit low for DOVORCE but still all over 0.9. Very high for WELLNESS.\n",
    "Shows strong performance in classifying both \"DIVORCE\" and \"WELLNESS\" articles.\n",
    "\n",
    "### KNN:\n",
    "Shows lower performance compared to other classifiers.\n",
    "\n",
    "### Deep Learning:\n",
    "Achieves high precision, recall, and F1-scores for both categories.\n",
    "Shows strong performance in classifying both \"DIVORCE\" and \"WELLNESS\" articles.\n",
    "\n",
    "### For the following task, I will use the two most suitable classifiers: : Random Forest and Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ed8158",
   "metadata": {
    "id": "32ed8158"
   },
   "source": [
    "10. Perform an error analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c711af3a",
   "metadata": {
    "id": "c711af3a"
   },
   "source": [
    "### Random Forest Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5b325",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "24f5b325",
    "outputId": "f5cac5d1-6775-467b-c663-3eb9ccc4259a"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_rf = confusion_matrix(y_valid, rf_pred)\n",
    "ax_rf = plt.subplot()\n",
    "sns.heatmap(cm_rf, annot=True, fmt='g', ax=ax_rf)\n",
    "ax_rf.set_xlabel('Predicted labels')\n",
    "ax_rf.set_ylabel('True labels')\n",
    "ax_rf.set_title('Confusion Matrix - Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d306787b",
   "metadata": {
    "id": "d306787b"
   },
   "outputs": [],
   "source": [
    "# Error Analysis - Random Forest\n",
    "valid_data_rf = pd.DataFrame({'combined_text': X_valid, 'category': y_valid, 'predicted_category': rf_pred})\n",
    "misclassified_instances_rf = valid_data_rf[valid_data_rf['category'] != valid_data_rf['predicted_category']]\n",
    "misclassified_instances_rf.to_csv('error_analysis_rf_valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9bdc71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "5a9bdc71",
    "outputId": "22d75171-8d1d-4421-a351-ed823cb47c55"
   },
   "outputs": [],
   "source": [
    "misclassified_instances_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e38f6f",
   "metadata": {
    "id": "10e38f6f"
   },
   "source": [
    "### Naive Bayes Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c667e87",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "0c667e87",
    "outputId": "7f628e4b-776e-49c8-e02f-23c906d1b6de"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm_nb = confusion_matrix(y_valid, nb_pred)\n",
    "ax_nb = plt.subplot()\n",
    "sns.heatmap(cm_nb, annot=True, fmt='g', ax=ax_nb)\n",
    "ax_nb.set_xlabel('Predicted labels')\n",
    "ax_nb.set_ylabel('True labels')\n",
    "ax_nb.set_title('Confusion Matrix - Naive Bayes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba735da7",
   "metadata": {
    "id": "ba735da7"
   },
   "outputs": [],
   "source": [
    "# Error Analysis - Naive Bayes\n",
    "valid_data_nb = pd.DataFrame({'combined_text': X_valid, 'category': y_valid, 'predicted_category': nb_pred})\n",
    "misclassified_instances_nb = valid_data_nb[valid_data_nb['category'] != valid_data_nb['predicted_category']]\n",
    "misclassified_instances_nb.to_csv('error_analysis_nb_valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e099e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "a24e099e",
    "outputId": "a33f9c62-0218-4a8e-e2d4-f1c32a2cdd66"
   },
   "outputs": [],
   "source": [
    "misclassified_instances_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a44a3",
   "metadata": {
    "id": "209a44a3"
   },
   "source": [
    "10. Perform an error analysis for each model tested on the previous item. Comment on your results. Consider things like: did the different models classify the same sentences incorrectly? What have you learned from this analysis?\n",
    "\n",
    "Insights from the Confusion Matrix:  \n",
    "\n",
    "The confusion matrix shows that the Random Forest model / the Naive Bayes model performed well overall, with a large number of true positives (TP) and true negatives (TN).\n",
    "The number of false positives (FP) and false negatives (FN) is relatively low, indicating that the model's misclassifications are limited.\n",
    "\n",
    "Misclassified Instances:  \n",
    "Some patterns and observations from the misclassifications:\n",
    "\n",
    "Overlapping Themes: Some misclassified instances seem to contain overlapping themes or topics between the \"WELLNESS\" and \"DIVORCE\" categories. This overlap could make the classification challenging for the model.\n",
    "\n",
    "Contextual Ambiguity: In some cases, the model might have misclassified sentences due to contextual ambiguity or subtle nuances that could affect the category determination.\n",
    "\n",
    "Uncommon Phrases: The model could struggle with sentences that contain uncommon phrases, domain-specific terminology, or slang not present in the training data.\n",
    "\n",
    "Similar Sentence Structure: Some misclassifications might be due to sentences with similar structures but different meanings, leading the model to make incorrect predictions.\n",
    "\n",
    "Emotional Language: Sentences with emotionally charged or ambiguous language might lead to misclassifications, as the model might have difficulty understanding the underlying sentiment.\n",
    "\n",
    "Limited Data: Instances with fewer examples in the training data could be prone to misclassification, as the model may not have enough exposure to learn the patterns in those instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d223c153",
   "metadata": {
    "id": "d223c153"
   },
   "source": [
    "11. Apply at least one change to each classifier/model developed on Task 2 and redo your evaluation. Think of a change that can help improve the metric you are using to evaluate your models. This change can either be a change of a parameter, or a different preprocessing or any other change you may find interesting to implement after doing an error analysis. Depending on your primary metric, you may want to consider strategies to address the imbalance in your dataset. Save these models in an appropriate format. Comment on your choices and results. Could you achieve the benchmark you expected for this task?\n",
    "\n",
    "### For the previous code, I've considered a variety of changes and used the better performing version. Here are some of the adjustments I have tried, but below are the worse options.\n",
    "\n",
    "###  Change to classifier/model parameter\n",
    "In order to improve the performance of the classifier/model for unbalanced datasets, I queried how to parameterize it for such data.\n",
    "\n",
    "Random Forest Classifier:\n",
    "We can adjust the class_weight parameter in the Random Forest classifier to give more importance to the minority class (DIVORCE) during training. This can help mitigate the impact of class imbalance.\n",
    "\n",
    "Naive Bayes Classifier:\n",
    "For the Naive Bayes classifier, we can use the ComplementNB variant, It corrects the \"complement\" of each class's empirical probability, thereby handling imbalanced data more effectively.\n",
    "\n",
    "These parameter changes did not significantly change the performance of the classifier\n",
    "\n",
    "For the deep learning model, this parameter change can significantely improve the performance, But it is strongly recommended not to run it. When I run google colab, it needs to run for a whole day, and it cannot be saved after the connection is interrupted.\n",
    "model.fit(\n",
    "    x=train_dataset.shuffle(1000).batch(16),\n",
    "    validation_data=valid_dataset.batch(16),\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "### different preprocessing\n",
    "The text preprocessing can significantly improve model performance.\n",
    "I set up the preprocessor function at the beginning and each step improves the performance.\n",
    "\n",
    "### other change\n",
    "data_combined instead of data_headline can significantly improve model performance.\n",
    "\n",
    "Results have met the expected level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be223de1",
   "metadata": {
    "id": "be223de1"
   },
   "source": [
    "### Try different parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec155415",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "ec155415",
    "outputId": "f6717f93-23c7-4adf-9dda-cc1bb89a4221"
   },
   "outputs": [],
   "source": [
    "# Initialize the Random Forest classifier with class weights\n",
    "rf = RandomForestClassifier(n_estimators=200, class_weight='balanced')\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "rf.fit(X_train_matrix, y_train)\n",
    "\n",
    "# Initialize the Naive Bayes classifier with class weights\n",
    "naive_bayes = MultinomialNB(class_prior=None)\n",
    "# Use class_prior=None to ensure class weights are calculated based on the data\n",
    "naive_bayes.fit(X_train_matrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d18aba0",
   "metadata": {
    "id": "8d18aba0"
   },
   "outputs": [],
   "source": [
    "rf_pred = rf.predict(X_valid_matrix)\n",
    "nb_pred = naive_bayes.predict(X_valid_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484403b7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "484403b7",
    "outputId": "78da8ba8-cbb0-4400-ef09-3f484115e821"
   },
   "outputs": [],
   "source": [
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_valid, rf_pred))\n",
    "\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_valid, nb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9df8ed",
   "metadata": {
    "id": "ed9df8ed"
   },
   "source": [
    "Random Forest:\n",
    "\n",
    "The original Random Forest model achieved an overall accuracy of 96%, with precision, recall, and F1-score for both classes (DIVORCE and WELLNESS) in the high 90s range. This is a good performance.\n",
    "After changing the Random Forest classifier to use class weights (class_weight='balanced'), there was a slight decrease in performance in terms of recall for the DIVORCE class. The recall for the DIVORCE class dropped from 0.90 to 0.89.\n",
    "The weighted average F1-score for the Random Forest classifier remained the same after introducing class weights, indicating that the change did not have a substantial impact on the overall performance.\n",
    "\n",
    "Naive Bayes:\n",
    "\n",
    "Similarly, the original Naive Bayes model achieved an overall accuracy of 96%, with precision, recall, and F1-score for both classes (DIVORCE and WELLNESS) in the high 90s range. This is also a good performance.\n",
    "After incorporating class weights into the Naive Bayes classifier (class_prior=None), the performance remained virtually the same. There were no notable improvements or declines in precision, recall, or F1-scores for either class.\n",
    "\n",
    "The data might already be well-separated in the feature space, allowing both classifiers to perform well without much influence from class weights.\n",
    "It's possible that the original Random Forest and Naive Bayes models were already adequately handling class imbalance or were not significantly impacted by it in this specific dataset.\n",
    "The initial performance of both classifiers was already high, and class weights might not have been necessary in this particular scenario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32892151",
   "metadata": {
    "id": "32892151"
   },
   "source": [
    "### Try data_headline\n",
    "We can see that the performance of the classifier is significantly lower, and after this, I will only use the data_combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14640a7c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "14640a7c",
    "outputId": "84c8e4b4-2244-44d0-f7ca-34e1160f19ab"
   },
   "outputs": [],
   "source": [
    "data_headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d3178",
   "metadata": {
    "id": "440d3178"
   },
   "outputs": [],
   "source": [
    "Xh = data_headline['headline']\n",
    "yh = data_headline['category']\n",
    "# Split the dataset into training, validation, and test sets\n",
    "Xh_train_plus_valid, Xh_test, yh_train_plus_valid, yh_test = train_test_split(Xh, yh, random_state=0, test_size=0.2, train_size=0.8)\n",
    "Xh_train, Xh_valid, yh_train, yh_valid = train_test_split(Xh_train_plus_valid, yh_train_plus_valid, random_state=0, test_size=0.25, train_size=0.75)\n",
    "# Apply preprocessing to the text data\n",
    "Xh_train = Xh_train.apply(preprocess_text)\n",
    "Xh_valid = Xh_valid.apply(preprocess_text)\n",
    "# Create a numeric representation of the documents\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "Xh_train_matrix = vectorizer.fit_transform(Xh_train)\n",
    "Xh_valid_matrix = vectorizer.transform(Xh_valid)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "rf.fit(Xh_train_matrix, yh_train)\n",
    "# Train the Naive Bayes classifier\n",
    "naive_bayes.fit(Xh_train_matrix, yh_train)\n",
    "rf_predh = rf.predict(Xh_valid_matrix)\n",
    "nb_predh = naive_bayes.predict(Xh_valid_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13cc3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c13cc3a",
    "outputId": "e9d9277d-3787-4f44-ce37-8c647db2bd1e"
   },
   "outputs": [],
   "source": [
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(yh_valid, rf_predh))\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(classification_report(yh_valid, nb_predh))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad07a98",
   "metadata": {
    "id": "2ad07a98"
   },
   "source": [
    "### Try without preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff75ad7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "9ff75ad7",
    "outputId": "e67e046d-42be-4eaf-cd2e-9dbbaf01e541"
   },
   "outputs": [],
   "source": [
    "data_headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca8894",
   "metadata": {
    "id": "c5ca8894"
   },
   "outputs": [],
   "source": [
    "Xh = data_headline['headline']\n",
    "yh = data_headline['category']\n",
    "# Split the dataset into training, validation, and test sets\n",
    "Xh_train_plus_valid, Xh_test, yh_train_plus_valid, yh_test = train_test_split(Xh, yh, random_state=0, test_size=0.2, train_size=0.8)\n",
    "Xh_train, Xh_valid, yh_train, yh_valid = train_test_split(Xh_train_plus_valid, yh_train_plus_valid, random_state=0, test_size=0.25, train_size=0.75)\n",
    "# Create a numeric representation of the documents\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "Xh_train_matrix = vectorizer.fit_transform(Xh_train)\n",
    "Xh_valid_matrix = vectorizer.transform(Xh_valid)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "rf.fit(Xh_train_matrix, yh_train)\n",
    "# Train the Naive Bayes classifier\n",
    "naive_bayes.fit(Xh_train_matrix, yh_train)\n",
    "rf_predh = rf.predict(Xh_valid_matrix)\n",
    "nb_predh = naive_bayes.predict(Xh_valid_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba51268",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ba51268",
    "outputId": "892572ee-5786-4534-cc4f-f7442492b58f"
   },
   "outputs": [],
   "source": [
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(yh_valid, rf_predh))\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(classification_report(yh_valid, nb_predh))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ffcae",
   "metadata": {
    "id": "ff5ffcae"
   },
   "source": [
    "12.Merge your train and validation sets and perform cross validation using the classifiers from item 11. Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19162a8",
   "metadata": {
    "id": "c19162a8"
   },
   "outputs": [],
   "source": [
    "# Merge the training and validation sets\n",
    "X_train_plus_valid = pd.concat([train_data['preprocessed_text'], valid_data['preprocessed_text']])\n",
    "y_train_plus_valid = pd.concat([train_data['category'], valid_data['category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e0e17",
   "metadata": {
    "id": "702e0e17"
   },
   "outputs": [],
   "source": [
    "# Create a numeric representation of the documents\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_plus_valid_matrix = vectorizer.fit_transform(X_train_plus_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2bbe2f",
   "metadata": {
    "id": "5b2bbe2f"
   },
   "outputs": [],
   "source": [
    "# Initialize the classifiers with desired parameters\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "naive_bayes = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f3bf4",
   "metadata": {
    "id": "6d5f3bf4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Perform cross-validation for Random Forest\n",
    "cross_val_rf = cross_val_score(rf, X_train_plus_valid_matrix, y_train_plus_valid, cv=5)\n",
    "\n",
    "# Perform cross-validation for Naive Bayes\n",
    "cross_val_nb = cross_val_score(naive_bayes, X_train_plus_valid_matrix, y_train_plus_valid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b45d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b7b45d4c",
    "outputId": "e07bd46f-520d-4092-bc0d-46279195a1d8"
   },
   "outputs": [],
   "source": [
    "# Print the cross-validation scores\n",
    "print(\"Random Forest Cross-Validation Scores:\", cross_val_rf)\n",
    "print(\"Naive Bayes Cross-Validation Scores:\", cross_val_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a878b7d",
   "metadata": {
    "id": "0a878b7d"
   },
   "source": [
    "Cross-validation scores provide an estimate of the models' performance on unseen data and can serve as a good indicator of their generalization ability.\n",
    "\n",
    "The Random Forest model shows relatively consistent performance across different folds of the data, with cross-validation scores ranging from approximately 94.9% to 95.9%.\n",
    "The average cross-validation score is around 95.4%, indicating that the model performs reasonably well on unseen data, achieving an accuracy of about 95.4%.\n",
    "\n",
    "The Naive Bayes model also demonstrates consistent performance across different folds, with cross-validation scores ranging from approximately 93.9% to 95.2%.\n",
    "The average cross-validation score is around 94.6%, suggesting that the Naive Bayes model is slightly less accurate compared to the Random Forest model, achieving an average accuracy of about 94.6%.\n",
    "\n",
    "\n",
    "13. Choose the best model from the previous item, load it using the files created on item 11 and apply it to the test set (test.csv).Make sure you are preprocessing the test set exactly the same way you preprocessed the data you used to train the model.\n",
    "\n",
    "The Random Forest classifier has slightly higher cross-validation scores compared to Naive Bayes. The deep learning models also performed well, but often caused the program to crash. Therefore, I chose the Random Forest model as the best model.\n",
    "\n",
    "To ensure that the test set is preprocessed in exactly the same way as the data used to train the model. The same processing has been performed earlier, and here only to load the data.\n",
    "\n",
    "14. Retrain the best model from Task 3 (item 11) using the train and validation datasets and now apply to the test set. Did training the model with more data make any difference? Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd07bb",
   "metadata": {
    "id": "88fd07bb"
   },
   "outputs": [],
   "source": [
    "# Create a single CountVectorizer and fit it on the combined training and validation set\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_plus_valid_matrix = vectorizer.fit_transform(X_train_plus_valid)\n",
    "\n",
    "X_train_matrix = vectorizer.transform(X_train)\n",
    "X_valid_matrix = vectorizer.transform(X_valid)\n",
    "\n",
    "X_test_matrix = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1007a379",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "1007a379",
    "outputId": "b228f9ba-e458-4b66-d41a-e261bf478de3"
   },
   "outputs": [],
   "source": [
    "# Train the Random Forest classifier on the training dataset alone\n",
    "rf_train = RandomForestClassifier(n_estimators=100)\n",
    "rf_train.fit(X_train_matrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80aab2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "a80aab2c",
    "outputId": "f5e9f8ee-2698-4f90-9d63-42940f136dc4"
   },
   "outputs": [],
   "source": [
    "# Train the Random Forest classifier on the combined training and validation dataset\n",
    "rf_train_valid = RandomForestClassifier(n_estimators=100)\n",
    "rf_train_valid.fit(X_train_plus_valid_matrix, y_train_plus_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f05c28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38f05c28",
    "outputId": "addd46b9-db01-455f-d36a-3b6078c691c1"
   },
   "outputs": [],
   "source": [
    "X_test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62201638",
   "metadata": {
    "id": "62201638"
   },
   "outputs": [],
   "source": [
    "# Apply the Random Forest model to the test set\n",
    "y_pred_test_rf_train_valid = rf_train_valid.predict(X_test_matrix)\n",
    "y_pred_test_rf_train = rf_train.predict(X_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46592e5a",
   "metadata": {
    "id": "46592e5a"
   },
   "outputs": [],
   "source": [
    "# Evaluate the models on the test set\n",
    "accuracy_rf_train = accuracy_score(y_test, y_pred_test_rf_train)\n",
    "accuracy_rf_train_valid = accuracy_score(y_test, y_pred_test_rf_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d969b5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d969b5a",
    "outputId": "8ffd8e08-dbbb-4f5a-e116-2c281f372f59"
   },
   "outputs": [],
   "source": [
    "print(\"Test Set Accuracy - Random Forest trained on Train Data:\", accuracy_rf_train)\n",
    "print(\"Test Set Accuracy - Random Forest trained on Train + Validation Data:\", accuracy_rf_train_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb4ce8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39cb4ce8",
    "outputId": "c0534866-4c35-4d3c-b8b8-4e438b84b644"
   },
   "outputs": [],
   "source": [
    "print(\"Random Forest Classification Report - Train Data:\")\n",
    "print(classification_report(y_test, y_pred_test_rf_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c17003",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64c17003",
    "outputId": "1eced90e-8bbb-4da8-82c1-5db411694262"
   },
   "outputs": [],
   "source": [
    "print(\"Random Forest Classification Report - Train + Validation Data:\")\n",
    "print(classification_report(y_test, y_pred_test_rf_train_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de77630c",
   "metadata": {
    "id": "de77630c"
   },
   "source": [
    "Test Set Accuracy: The accuracy on the Test set increased from approximately 95.09% (trained on Train data) to 95.53% (trained on Train + Validation data). This suggests that the model trained on more data is better at making correct predictions on unseen examples.\n",
    "Precision, Recall, and F1-score: For both classes (DIVORCE and WELLNESS), the precision, recall, and F1-scores remain high in both cases. This indicates that the model is good at correctly identifying instances of each class, with the combined dataset model slightly outperforming the Train data model.\n",
    "Overall Performance: The macro and weighted average F1-scores for the Train + Validation data model are slightly higher than those for the Train data model. This means the model trained on more data achieves a better balance between class-specific and overall performance.\n",
    "Class Imbalance: Since the performance metrics for both classes are high, it appears that the model handles the class imbalance well, which is evident from the similar precision, recall, and F1-scores for both classes.\n",
    "Overall, the increase in accuracy and slight improvement in other performance metrics suggest that training the model with more data (Train + Validation) has positively affected its performance. It showcases how leveraging additional data for training can lead to better generalization and robustness of the model, making it more effective in making accurate predictions on unseen data (Test set). However, the improvement might be considered modest, as the increase in accuracy is not substantial, but any improvement in real-world applications is valuable."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
